{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install --upgrade tensorflow -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Flatten, Dense, Lambda, Dropout, Activation)\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D)\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "STYLES_CSV_PATH = \"/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/data/styles.csv\"\n",
    "IMAGES_PATH = \"/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/data/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 44424\n",
      "Total Columns: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>masterCategory</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>articleType</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>usage</th>\n",
       "      <th>productDisplayName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15970</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Shirts</td>\n",
       "      <td>Navy Blue</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Turtle Check Men Navy Blue Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39386</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Peter England Men Party Blue Jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59263</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Titan Women Silver Watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21379</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Track Pants</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Manchester United Men Solid Black Track Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53759</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Puma Men Grey T-shirt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id gender masterCategory subCategory  articleType baseColour  season  \\\n",
       "0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n",
       "1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n",
       "2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n",
       "3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n",
       "4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n",
       "\n",
       "     year   usage                             productDisplayName  \n",
       "0  2011.0  Casual               Turtle Check Men Navy Blue Shirt  \n",
       "1  2012.0  Casual             Peter England Men Party Blue Jeans  \n",
       "2  2016.0  Casual                       Titan Women Silver Watch  \n",
       "3  2011.0  Casual  Manchester United Men Solid Black Track Pants  \n",
       "4  2012.0  Casual                          Puma Men Grey T-shirt  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(STYLES_CSV_PATH, error_bad_lines = False, warn_bad_lines=False)\n",
    "print(f\"Total Rows: {df.shape[0]}\\nTotal Columns: {df.shape[1]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN Count:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "gender                  0\n",
       "masterCategory          0\n",
       "subCategory             0\n",
       "articleType             0\n",
       "baseColour             15\n",
       "season                 21\n",
       "year                    1\n",
       "usage                 317\n",
       "productDisplayName      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('NaN Count:')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.drop(['gender', 'articleType','season','usage','year', 'productDisplayName', 'masterCategory', 'subCategory'], axis=1)\n",
    "df = df.sample(10000)\n",
    "df = df[df['id'].isin([int(i.split('.')[0]) for i in os.listdir(IMAGES_PATH)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseColour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28125</th>\n",
       "      <td>Purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>Grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23599</th>\n",
       "      <td>Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37684</th>\n",
       "      <td>Navy Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42112</th>\n",
       "      <td>Brown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      baseColour\n",
       "28125     Purple\n",
       "10000       Grey\n",
       "23599      Brown\n",
       "37684  Navy Blue\n",
       "42112      Brown"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Colour Values:\n",
      "Purple\n",
      "Grey\n",
      "Brown\n",
      "Navy Blue\n",
      "Black\n",
      "Silver\n",
      "Green\n",
      "Orange\n",
      "White\n",
      "Blue\n",
      "Other\n",
      "Multi\n",
      "Beige\n",
      "Steel\n",
      "Yellow\n",
      "Olive\n",
      "Pink\n",
      "Gold\n",
      "Red\n",
      "Maroon\n",
      "Cream\n"
     ]
    }
   ],
   "source": [
    "unique_colors = df['baseColour'].unique()\n",
    "\n",
    "# Print the unique color values\n",
    "print(\"Unique Colour Values:\")\n",
    "for color in unique_colors:\n",
    "  print(color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df['id'].apply(lambda x: IMAGES_PATH+str(x) +'.jpg')\n",
    "image_ids = df.pop('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_values(x):\n",
    "    x_vc = df[x].value_counts()\n",
    "    x_other = x_vc[x_vc<50].index\n",
    "    df.loc[df[x].isin(x_other),x] = 'Other'\n",
    "    \n",
    "for col in df.columns:\n",
    "    bin_values(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [04:12<00:00, 39.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet import preprocess_input\n",
    "\n",
    "IMAGE_DIMS = (60, 60, 3)\n",
    "\n",
    "def load_image(imagePath):\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "image_data = []\n",
    "for img_path in tqdm(image_ids):\n",
    "    image_data.append(load_image(img_path))\n",
    "    \n",
    "image_data = np.array(image_data, dtype=\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseColourLB = LabelBinarizer()\n",
    "\n",
    "\n",
    "baseColourLabels = baseColourLB.fit_transform(np.array(df['baseColour'].values))\n",
    "\n",
    "split = train_test_split(image_data,\n",
    "                         baseColourLabels, \n",
    "                         test_size=0.2, random_state=42)\n",
    "\n",
    "(trainX, testX,\n",
    " trainBaseColourY, testBaseColourY) = split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_branch(res_input, n_out, act_type, name):\n",
    "    z = Dense(512, activation=\"relu\")(res_input)\n",
    "    z = Dense(256, activation='relu')(z)\n",
    "    z = Dense(128, activation='relu')(z)\n",
    "#     z = BatchNormalization()(z)\n",
    "#     z = Dropout(0.5)(z)\n",
    "    z = Dense(n_out)(z)\n",
    "    z = Activation(act_type, name=name+'_output')(z)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(width, height):\n",
    "\n",
    "    # -------------------------\n",
    "    res50 = ResNet50(weights='imagenet', include_top=False, input_shape=IMAGE_DIMS)\n",
    "    res50.trainable=False\n",
    "    inputs = Input(shape=IMAGE_DIMS)\n",
    "    x = res50(inputs, training=False)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    # -------------------------\n",
    "\n",
    "    color_branch = make_branch(x, len(baseColourLB.classes_), 'softmax', 'color')\n",
    "\n",
    "\n",
    "    model = Model(inputs=inputs,\n",
    "                outputs=[ color_branch])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "EPOCHS = 25\n",
    "INIT_LR = 1e-5\n",
    "BS = 32\n",
    "\n",
    "opt = Adam(learning_rate=INIT_LR)\n",
    "model.compile(optimizer=opt, loss=losses, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 88s 342ms/step - loss: 2.3728 - accuracy: 0.3316 - val_loss: 1.9999 - val_accuracy: 0.4400\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 90s 359ms/step - loss: 1.7779 - accuracy: 0.4959 - val_loss: 1.7944 - val_accuracy: 0.4905\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 85s 340ms/step - loss: 1.4915 - accuracy: 0.5739 - val_loss: 1.6870 - val_accuracy: 0.5085\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 85s 340ms/step - loss: 1.2870 - accuracy: 0.6276 - val_loss: 1.6185 - val_accuracy: 0.5280\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 85s 340ms/step - loss: 1.1169 - accuracy: 0.6811 - val_loss: 1.5916 - val_accuracy: 0.5305\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 85s 340ms/step - loss: 0.9779 - accuracy: 0.7287 - val_loss: 1.5549 - val_accuracy: 0.5425\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 86s 343ms/step - loss: 0.8594 - accuracy: 0.7601 - val_loss: 1.5416 - val_accuracy: 0.5480\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 91s 363ms/step - loss: 0.7564 - accuracy: 0.8014 - val_loss: 1.5428 - val_accuracy: 0.5465\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 90s 361ms/step - loss: 0.6680 - accuracy: 0.8310 - val_loss: 1.5340 - val_accuracy: 0.5485\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 85s 342ms/step - loss: 0.5893 - accuracy: 0.8554 - val_loss: 1.5311 - val_accuracy: 0.5495\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 86s 342ms/step - loss: 0.5190 - accuracy: 0.8776 - val_loss: 1.5491 - val_accuracy: 0.5565\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 85s 341ms/step - loss: 0.4596 - accuracy: 0.8980 - val_loss: 1.5443 - val_accuracy: 0.5540\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 85s 342ms/step - loss: 0.4047 - accuracy: 0.9161 - val_loss: 1.5545 - val_accuracy: 0.5575\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 85s 342ms/step - loss: 0.3564 - accuracy: 0.9311 - val_loss: 1.5744 - val_accuracy: 0.5545\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 86s 342ms/step - loss: 0.3143 - accuracy: 0.9431 - val_loss: 1.5899 - val_accuracy: 0.5545\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 86s 344ms/step - loss: 0.2740 - accuracy: 0.9557 - val_loss: 1.5960 - val_accuracy: 0.5560\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 86s 342ms/step - loss: 0.2416 - accuracy: 0.9669 - val_loss: 1.6045 - val_accuracy: 0.5530\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 85s 342ms/step - loss: 0.2102 - accuracy: 0.9729 - val_loss: 1.6329 - val_accuracy: 0.5535\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 86s 343ms/step - loss: 0.1850 - accuracy: 0.9762 - val_loss: 1.6539 - val_accuracy: 0.5475\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 86s 343ms/step - loss: 0.1611 - accuracy: 0.9827 - val_loss: 1.6752 - val_accuracy: 0.5515\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 86s 343ms/step - loss: 0.1412 - accuracy: 0.9855 - val_loss: 1.6919 - val_accuracy: 0.5510\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 87s 347ms/step - loss: 0.1230 - accuracy: 0.9904 - val_loss: 1.7183 - val_accuracy: 0.5560\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 86s 344ms/step - loss: 0.1088 - accuracy: 0.9916 - val_loss: 1.7392 - val_accuracy: 0.5530\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 86s 343ms/step - loss: 0.0937 - accuracy: 0.9948 - val_loss: 1.7508 - val_accuracy: 0.5535\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 85s 342ms/step - loss: 0.0813 - accuracy: 0.9952 - val_loss: 1.7856 - val_accuracy: 0.5505\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(trainX,\n",
    "    {\"color_output\": trainBaseColourY},\n",
    "    validation_data=(testX, \n",
    "    {\"color_output\": testBaseColourY}),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BS,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/models/model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7856084108352661\n",
      "Accuracy: 55.05 %\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(testX, {\"color_output\": testBaseColourY}, batch_size=32, verbose=0)\n",
    "print('Loss:', res[0])\n",
    "# Assuming you have one metric (accuracy), it will be at index 1\n",
    "print('Accuracy:', round(res[1] * 100, 2), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "Color: Grey (86.88%) ----- White\n"
     ]
    }
   ],
   "source": [
    "idx=3\n",
    "\n",
    "colorProba= model.predict(np.expand_dims(testX[idx], axis=0))\n",
    "\n",
    "\n",
    "colorIdx = colorProba[0].argmax()\n",
    "colorLabel = baseColourLB.classes_[colorIdx]\n",
    "\n",
    "\n",
    "colorText = \"Color: {} ({:.2f}%)\".format(colorLabel, colorProba[0][colorIdx] * 100)\n",
    "\n",
    "\n",
    "\n",
    "print(colorText, '-----',baseColourLB.classes_[testBaseColourY[idx].argmax()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with custom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f08808f0680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f08808f0680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 609ms/step\n",
      "Predicted color: Maroon\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Load the model\n",
    "model_path = '/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/models/model.h5' # or 'my_model' for the SavedModel format\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Load and preprocess an image\n",
    "def load_and_preprocess_image(img_path, target_size=(224, 224)):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "    return preprocess_input(img_array_expanded_dims)\n",
    "\n",
    "# Assuming you have an image 'test_image.jpg'\n",
    "img_path = '/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/data/images2.jpeg'\n",
    "preprocessed_img = load_and_preprocess_image(img_path, target_size=(60, 60))  # Make sure to pass the correct target size\n",
    "\n",
    "# Predict the color\n",
    "predictions = model.predict(preprocessed_img)\n",
    "\n",
    "# Assuming your model outputs probabilities for each class in the 'color' branch\n",
    "# and you have a list of class names corresponding to the model's outputs\n",
    "color_classes =[\n",
    "    \"Purple\", \"Grey\", \"Brown\", \"Navy Blue\", \"Black\", \"Silver\",\n",
    "    \"Green\", \"Orange\", \"White\", \"Blue\", \"Other\", \"Multi\", \"Beige\",\n",
    "    \"Steel\", \"Yellow\", \"Olive\", \"Pink\", \"Gold\", \"Red\", \"Maroon\", \"Cream\",\n",
    "    \"Charcoal\", \"Skin\", \"Grey Melange\", \"Tan\", \"Khaki\", \"Turquoise Blue\",\n",
    "    \"Teal\", \"Mustard\", \"Off White\", \"Burgundy\", \"Magenta\", \"Lavender\",\n",
    "    \"Peach\", \"Copper\", \"Rust\", \"Mauve\", \"Nude\", \"Metallic\", \"Sea Green\",\n",
    "    \"Rose\", \"Fluorescent Green\", \"Bronze\", \"Taupe\", \"Coffee Brown\",\n",
    "    \"Lime Green\", \"Mushroom Brown\"\n",
    "]\n",
    "  # Example class names\n",
    "predicted_color = color_classes[np.argmax(predictions)]\n",
    "\n",
    "print(f'Predicted color: {predicted_color}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
